# 数据预处理

1. 缺失值、异常值
2. 数据清洗！！

# 特征选择

### 目的

* 寻找最优特征子集：剔除不相关、冗余的特征
* 减少特征数量、降维，增强泛化性，防止过拟合
* 增强对特征间关系的理解

### 方法：

1. 去掉取值变化小的特征
2. **单变量特征选择**：衡量每个特征与相应变量的关系
3. **通过正则化引入惩罚**

也就是三大类：
* 过滤法
按照相关性等对每个特征进行评分，然后设定阈值或选择TopK。
* 包装法
根据目标函数每次选择（或排除）若干特征。
* 嵌入法
用机器学习模型训练每个特征的权重。

**单变量特征选择（过滤法和嵌入法）**：
* pearson相关系数
只能评估线性关系（一般最开始都会跑着看一下），对非线性关系不敏感（趋于0）
0表示不相关，1表示正相关，-1表示负相关

* 互信息和最大信息系数MIC
可以解决非线性关系，取值在[0,1]

* 基于学习模型的特征排序
其实就是为每个特征建立一个预测模型，然后评估效果
通常使用拓展线性模型或者树模型，可以评估非线性关系
结合交叉验证使用

* 距离相关系数

* 卡方验证

* 稳定性选择
在随机选择的特征子集上进行特征选择，然后汇总结果

* 递归特征消除RFE
每次选出最好（最坏）的特征，然后在剩余子集中继续筛选

**正则化方法（包装法）**：一些回归方法会在特征上增加一个权重，本身就代表了特征的相关性
* 线性回归
LR+L1正则：Lasso，学习到的特征很稀疏，弱特征系数为0
LR+L2正则：Ridge，系数更平均

* 随机森林
1. 平均不纯度减少
计算每个特征减少了树的多少不纯度

2. 平均精确率减少
每次将某一特征的各样本打乱，然后看模型精确度下降多少


### 流程
1. 生成子集：搜索**特征子集**，为评价函数提供特征子集
2. 评价函数：评价特征子集的好坏
3. 停止准则：与评价函数相关，一般是**阈值**，评价函数达到一定标准后就可停止搜索
4. 验证过程：在**验证集**上验证选出来的特征子集的有效性

# 数据分析

1. 统计性描述
2. 相关性分析（相关系数）

### 数据集分析

* 数据集划分
k折交叉验证

* 类别不平衡
即分类任务中不同类别训练数据数目差别很大

1. 随机上采样
通过简单复制来增加少数样本的数目
2. 合成少数类过采样技术SMOTE
对少数样本进行分析，并

stacking特征

* 特征转换


### 模型选择

* 模型评价指标
F1、AUC

* 参数调整
网格搜索GridSearch
